{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72478c96-c518-4858-84cb-f7a575cf5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取目标汉字截图，利用百度接口识别汉字\n",
    "# 根据汉字到缓存中随机获取对应的汉字图片，若缓存中没有，利用函数生成汉字图片，该图片作为孪生神经网络的输入之一\n",
    "# 获取验证码背景图，利用yolov5检测图片中的汉字，保存坐标位置并剪切汉字图片保存，作为孪生神经网络的输入之一\n",
    "# 经过以上的步骤，利用孪生神经网络按照顺序依次判断目标汉字图片与背景图中检测的图片的文字相似度，找到相似度最高的图片的坐标位置\n",
    "# 最终得到排序后的坐标位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d21cffc-d178-4967-a98a-acb4df75435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "import time\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageOps, ImageFilter\n",
    "from io import BytesIO\n",
    "import os\n",
    "from IPython.display import clear_output as clear\n",
    "import sys\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import shutil\n",
    "import cv2\n",
    "import urllib\n",
    "import base64\n",
    "import scipy.misc\n",
    "import scipy.signal\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e27e377e-15dc-4d06-8c61-315266e75f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用百度接口识别汉字\n",
    "API_KEY = \"7gA8YqNKUIBdX5HIenGEGBzm\"\n",
    "SECRET_KEY = \"tFrsRHSIRdvsGLIhaVkfThU8BR74S3Go\"\n",
    "\n",
    "def get_access_token():\n",
    "    url = \"https://aip.baidubce.com/oauth/2.0/token\"\n",
    "    params = {\"grant_type\": \"client_credentials\", \"client_id\": API_KEY, \"client_secret\": SECRET_KEY}\n",
    "    return str(requests.post(url, params=params).json().get(\"access_token\"))\n",
    "\n",
    "def get_file_content_as_base64(path, urlencoded=False):\n",
    "    \"\"\"\n",
    "    获取文件base64编码\n",
    "    :param path: 文件路径\n",
    "    :param urlencoded: 是否对结果进行urlencoded \n",
    "    :return: base64编码信息\n",
    "    \"\"\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        content = base64.b64encode(f.read()).decode(\"utf8\")\n",
    "        if urlencoded:\n",
    "            content = urllib.parse.quote_plus(content)\n",
    "    return content\n",
    "\n",
    "def recog_chars_baidu(img_path):\n",
    "    target_words = []\n",
    "    url = \"https://aip.baidubce.com/rest/2.0/ocr/v1/accurate_basic?access_token=\" + get_access_token()\n",
    "    headers = {\n",
    "        'Content-Type': 'application/x-www-form-urlencoded',\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "    image = get_file_content_as_base64(img_path, True)\n",
    "    payload = 'image=' + image\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    words = response.json()['words_result']\n",
    "    for item in words:\n",
    "        word = item['words']\n",
    "        target_words.extend(list(word))\n",
    "    \n",
    "    if len(target_words) < 3:\n",
    "        raise ValueError(\"目前暂不支持此类型验证码识别\")\n",
    "    \n",
    "    return target_words\n",
    "\n",
    "def convert_2d_1(r):\n",
    "    r_ext = np.zeros((r.shape[0] * 2, r.shape[1] * 2))\n",
    "    for i in range(r.shape[0]):\n",
    "        for j in range(r.shape[1]):\n",
    "            r_ext[i][j] = r[i][j]\n",
    "\n",
    "    r_ext_fu = np.fft.fft2(r_ext)\n",
    "    r_ext_fu = np.fft.fftshift(r_ext_fu)\n",
    "\n",
    "    # 截止频率为 100\n",
    "    d0 = 100\n",
    "    # 频率域中心坐标\n",
    "    center = (r_ext_fu.shape[0] // 2, r_ext_fu.shape[1] // 2)\n",
    "    h = np.empty(r_ext_fu.shape)\n",
    "    # 绘制滤波器 H(u, v)\n",
    "    for u in range(h.shape[0]):\n",
    "        for v in range(h.shape[1]):\n",
    "            duv = ((u - center[0]) ** 2 + (v - center[1]) ** 2) ** 0.65\n",
    "            h[u][v] = duv < d0\n",
    "\n",
    "    s_ext_fu = r_ext_fu * h\n",
    "    s_ext = np.fft.ifft2(np.fft.ifftshift(s_ext_fu))\n",
    "    s_ext = np.abs(s_ext)\n",
    "    s = s_ext[0:r.shape[0], 0:r.shape[1]]\n",
    "\n",
    "    for i in range(s.shape[0]):\n",
    "        for j in range(s.shape[1]):\n",
    "            s[i][j] = min(max(s[i][j], 0), 255)\n",
    "\n",
    "    return s.astype(np.uint8)\n",
    "\n",
    "\n",
    "def convert_3d_1(r):\n",
    "    s_dsplit = []\n",
    "    for d in range(r.shape[2]):\n",
    "        rr = r[:, :, d]\n",
    "        ss = convert_2d_1(rr)\n",
    "        s_dsplit.append(ss)\n",
    "    s = np.dstack(s_dsplit)\n",
    "    return s\n",
    "\n",
    "def convert_2d_2(r):\n",
    "    # 滤波掩模\n",
    "    window = np.array([\n",
    "        [0, -1, 0],\n",
    "        [-1, 5, -1],\n",
    "        [0, -1, 0]\n",
    "    ])\n",
    "    s = scipy.signal.convolve2d(r, window, mode='same', boundary='symm')\n",
    "    # 像素值如果大于 255 则取 255, 小于 0 则取 0\n",
    "    for i in range(s.shape[0]):\n",
    "        for j in range(s.shape[1]):\n",
    "            s[i][j] = min(max(0, s[i][j]), 255)\n",
    "    s = s.astype(np.uint8)\n",
    "    return s\n",
    "\n",
    "\n",
    "def convert_3d_2(r):\n",
    "    s_dsplit = []\n",
    "    for d in range(r.shape[2]):\n",
    "        rr = r[:, :, d]\n",
    "        ss = convert_2d_2(rr)\n",
    "        s_dsplit.append(ss)\n",
    "    s = np.dstack(s_dsplit)\n",
    "    return s\n",
    "\n",
    "def convert_2d_3(r):\n",
    "    n = 1\n",
    "    s = scipy.ndimage.median_filter(r, (n, n))\n",
    "    return s.astype(np.uint8)\n",
    "\n",
    "\n",
    "def convert_3d_3(r):\n",
    "    s_dsplit = []\n",
    "    for d in range(r.shape[2]):\n",
    "        rr = r[:, :, d]\n",
    "        ss = convert_2d_3(rr)\n",
    "        s_dsplit.append(ss)\n",
    "    s = np.dstack(s_dsplit)\n",
    "    return s\n",
    "\n",
    "def convert(img):\n",
    "    im_mat = np.asarray(img)\n",
    "    im_converted_mat = convert_3d_1(im_mat)\n",
    "    im_converted = Image.fromarray(im_converted_mat)\n",
    "    im_mat = np.asarray(im_converted)\n",
    "    im_converted_mat = convert_3d_2(im_mat)\n",
    "    im_converted = Image.fromarray(im_converted_mat)\n",
    "    im_mat = np.asarray(im_converted)\n",
    "    im_converted_mat = convert_3d_3(im_mat)\n",
    "    im_converted = Image.fromarray(im_converted_mat)\n",
    "    return im_converted\n",
    "\n",
    "def get_locate(i):\n",
    "    loc_box = []\n",
    "    width, height = 300, 200\n",
    "    # background = Image.open(f'./images/{i}.jpg')\n",
    "    with open(f'./detect_labels/{i}.txt', 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            box = line.split(' ')\n",
    "            x_center = width * float(box[1])  # 左上点的x坐标  \n",
    "            y_center = height * float(box[2])  # 左上点的y坐标\n",
    "            w = round(width * float(box[3]))  # 图片width\n",
    "            h = round(height * float(box[4]))  # 图片height\n",
    "            lefttopx = math.ceil(x_center - w / 2.0)\n",
    "            lefttopy = math.ceil(y_center - h / 2.0)\n",
    "            loc_box.append((lefttopx, lefttopy, lefttopx + w, lefttopy + h))\n",
    "    return loc_box\n",
    "\n",
    "def generate_char_img(lab, colors, bg_idx, crop_box, font_path='./中文像素字体.ttf'):\n",
    "    img = Image.new('RGBA', (52, 52))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = ImageFont.truetype(font_path, 46)\n",
    "    c1, c2 = random.choice(colors)\n",
    "    draw.text((2, 2), lab, font=font, fill=c1)\n",
    "    draw.text((4, 4), lab, font=font, fill=c1)\n",
    "    draw.text((2, 4), lab, font=font, fill=c1)\n",
    "    draw.text((4, 2), lab, font=font, fill=c1)\n",
    "    draw.text((3, 3), lab, font=font, fill=c2)\n",
    "\n",
    "    img_convert = convert(img)\n",
    "    angle = random.randint(-45, 45)\n",
    "    img_convert = img_convert.rotate(angle=angle)\n",
    "\n",
    "    i = random.choice(bg_idx)\n",
    "    loc_box = get_locate(i)\n",
    "    back_img = Image.open(f'./images/{i}.jpg')\n",
    "    _, _, _, mask = img_convert.split()\n",
    "    while True:\n",
    "        x1, y1, x2, y2 = random.choice(crop_box)\n",
    "        for leftx, lefty, rightx, righty in loc_box:\n",
    "            if (x1>rightx) or (y1>righty) or (x2<leftx) or (y2<lefty):\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            back_img.paste(img_convert, box=(x1, y1), mask=mask)\n",
    "            crop_img = back_img.crop((x1, y1, x2, y2))\n",
    "            break\n",
    "    return crop_img\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, image_size, pretrained=False):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        self.features_net = models.vgg11_bn(pretrained=False)\n",
    "        if pretrained:\n",
    "            params = torch.load('./model/vgg11_bn-6002323d.pth')\n",
    "            self.features_net.load_state_dict(params)\n",
    "        del self.features_net.avgpool\n",
    "        del self.features_net.classifier\n",
    "        \n",
    "        height, width = image_size[0], image_size[1]\n",
    "        for _ in range(5):\n",
    "            height //= 2\n",
    "            width //= 2\n",
    "        flat_shape = 512 * height * width\n",
    "        self.match_net = nn.Sequential(\n",
    "            nn.Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flat_shape, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.features_net.features(x1)\n",
    "        x2 = self.features_net.features(x2)\n",
    "\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        x = self.match_net(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def check_diff(img_0, img_1, trf, model, device):\n",
    "    img_0 = trf(img_0).unsqueeze(0)\n",
    "    img_1 = trf(img_1).unsqueeze(0)\n",
    "    img_0 = img_0.to(device)\n",
    "    img_1 = img_1.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    pred = model(img_0, img_1)\n",
    "    pred = nn.functional.sigmoid(pred.squeeze(-1))\n",
    "    \n",
    "    return pred.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f55e4fc-fb9b-4d3e-8373-f67d417a7240",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [('#C13808', '#FFF111'), ('#0023A7', '#0BF29E'), ('#6DCDF4', '#E111F9'), ('#22258C', '#7E0300'), ('#D55929', '#8513D4')]\n",
    "crop_box = [(0, 0, 52, 52), (124, 0, 176, 52), (248, 0, 300, 52), (0, 74, 52, 126), (124, 74, 176, 126), (248, 74, 300, 126), (0, 148, 52, 200), (124, 148, 176, 200), (248, 148, 300, 200)]\n",
    "bg_idx = [i[:-4] for i in os.listdir('./images/')]\n",
    "classes = os.listdir('./classes/')\n",
    "\n",
    "img_size = (112, 112)\n",
    "# norm_mean = [0.485, 0.456, 0.406]\n",
    "# norm_std = [0.229, 0.224, 0.225]\n",
    "trf = transforms.Compose([\n",
    "    transforms.Resize(img_size), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "model_path = './model/siamese_gpu_08_02.pt'\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = SiameseNetwork(image_size=img_size)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58379099-f2f7-4d24-b9e8-934393e336b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ChromeOptions()\n",
    "options.add_argument('user-agent=\"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36\"')\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--ssl-protocol=any')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_argument('user-agent=ywy')\n",
    "options.add_argument('--ignore-urlfetcher-cert-requests')\n",
    "options.add_argument('--ignore-ssl-errors')\n",
    "options.add_experimental_option('excludeSwitches', ['enable-automation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61e43bd1-7c5c-42ec-82f0-54d66f09c50f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidSessionIdException",
     "evalue": "Message: invalid session id\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00007FF6CD9B4A62+57106]\n\t(No symbol) [0x00007FF6CD92CF52]\n\t(No symbol) [0x00007FF6CD7FE17D]\n\t(No symbol) [0x00007FF6CD82CA69]\n\t(No symbol) [0x00007FF6CD82E064]\n\tGetHandleVerifier [0x00007FF6CDC64222+2873042]\n\tGetHandleVerifier [0x00007FF6CDCB6590+3209792]\n\tGetHandleVerifier [0x00007FF6CDCAF3AF+3180639]\n\tGetHandleVerifier [0x00007FF6CDA45F25+652245]\n\t(No symbol) [0x00007FF6CD938618]\n\t(No symbol) [0x00007FF6CD9347C4]\n\t(No symbol) [0x00007FF6CD9348BC]\n\t(No symbol) [0x00007FF6CD924C33]\n\tBaseThreadInitThunk [0x00007FFF57917614+20]\n\tRtlUserThreadStart [0x00007FFF591C26B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidSessionIdException\u001b[0m                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 103>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# driver.refresh()\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# time.sleep(3)\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# break\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     driver\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 103\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\anaconda3\\envs\\spider\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:456\u001b[0m, in \u001b[0;36mWebDriver.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;124;03m\"\"\"Closes the current window.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m    :Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03m            driver.close()\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLOSE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mF:\\anaconda3\\envs\\spider\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:345\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    343\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 345\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mF:\\anaconda3\\envs\\spider\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mInvalidSessionIdException\u001b[0m: Message: invalid session id\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00007FF6CD9B4A62+57106]\n\t(No symbol) [0x00007FF6CD92CF52]\n\t(No symbol) [0x00007FF6CD7FE17D]\n\t(No symbol) [0x00007FF6CD82CA69]\n\t(No symbol) [0x00007FF6CD82E064]\n\tGetHandleVerifier [0x00007FF6CDC64222+2873042]\n\tGetHandleVerifier [0x00007FF6CDCB6590+3209792]\n\tGetHandleVerifier [0x00007FF6CDCAF3AF+3180639]\n\tGetHandleVerifier [0x00007FF6CDA45F25+652245]\n\t(No symbol) [0x00007FF6CD938618]\n\t(No symbol) [0x00007FF6CD9347C4]\n\t(No symbol) [0x00007FF6CD9348BC]\n\t(No symbol) [0x00007FF6CD924C33]\n\tBaseThreadInitThunk [0x00007FFF57917614+20]\n\tRtlUserThreadStart [0x00007FFF591C26B1+33]\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(options=options)\n",
    "driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "    \"source\": \"\"\"\n",
    "    Object.defineProperty(navigator, 'webdriver', {\n",
    "      get: () => undefined\n",
    "    })\n",
    "  \"\"\"\n",
    "})\n",
    "driver.get('https://www.gsxt.gov.cn/index.html')\n",
    "time.sleep(5)\n",
    "\n",
    "input_box = driver.find_element(By.ID, 'keyword')\n",
    "input_box.send_keys('德信行')\n",
    "time.sleep(1)\n",
    "driver.find_element(By.ID, 'btn_query').click()\n",
    "time.sleep(3)\n",
    "\n",
    "box = driver.find_element(By.XPATH, '/html/body/div[7]/div[1]/div[1]/div[1]/div[1]/div[1]')\n",
    "text = box.get_attribute('innerText')\n",
    "if text == '请在下图依次点击':\n",
    "    # s = ''.join(random.sample(string.ascii_letters + string.digits, 4))\n",
    "    driver.find_element(By.XPATH, '/html/body/div[7]/div[1]/div[1]/div[1]/div[1]/div[2]').screenshot('./test/chars.png')\n",
    "    target_words = recog_chars_baidu('./test/chars.png')\n",
    "    # print(target_words)\n",
    "    \n",
    "    # 根据汉字到缓存中随机获取对应的汉字图片，若缓存中没有，利用函数生成汉字图片，该图片作为孪生神经网络的输入之一\n",
    "    target_imgs = []\n",
    "    for word in target_words:\n",
    "        if word in classes:\n",
    "            tmp = random.choice(os.listdir(f'./classes/{word}/'))\n",
    "            img = Image.open(f'./classes/{word}/{tmp}')\n",
    "            target_imgs.append(img)\n",
    "        else:\n",
    "            img = generate_char_img(word, colors, bg_idx, crop_box)\n",
    "            target_imgs.append(img)\n",
    "\n",
    "    # s = ''.join(random.sample(string.ascii_letters + string.digits, 4))\n",
    "    style = driver.find_element(By.XPATH, '/html/body/div[7]/div[1]/div[1]/div[2]/div/div/div[1]/div[1]').get_attribute('style')\n",
    "    url = style[23:-3]\n",
    "    content = requests.get(url).content\n",
    "    with open('./test/background.jpg', 'wb') as f:\n",
    "        f.write(content)\n",
    "    shutil.copy('./test/background.jpg', 'D:/yolo_dataset')\n",
    "    %run ./model/yolov5/detect.py --weight ./model/yolov5/runs/train/exp4/weights/best.pt --source D:/yolo_dataset/background.jpg --save-txt --conf-thres 0.5 --line-thickness 1 --img 320 --project ./results/detect/ --device cpu\n",
    "    background = Image.open(BytesIO(content))\n",
    "    width, height = background.size\n",
    "    num = len(os.listdir('./results/detect/'))\n",
    "    location = {}\n",
    "    with open(f'./results/detect/exp{str(num)}/labels/background.txt', 'r', encoding='utf8') as f:\n",
    "        # if len(f.readlines()) != 3:\n",
    "        #     print(i)\n",
    "        for i, line in enumerate(f):\n",
    "            box = line.split(' ')\n",
    "            x_center = width * float(box[1])  # 左上点的x坐标  \n",
    "            y_center = height * float(box[2])  # 左上点的y坐标\n",
    "            w = round(width * float(box[3]))  # 图片width\n",
    "            h = round(height * float(box[4]))  # 图片height\n",
    "            lefttopx = math.ceil(x_center - w / 2.0)\n",
    "            lefttopy = math.ceil(y_center - h / 2.0)\n",
    "            crop_img = background.crop((lefttopx, lefttopy, lefttopx + w, lefttopy + h))\n",
    "            # s = ''.join(random.sample(string.ascii_letters + string.digits, 5))\n",
    "            crop_img.save(f'./test/images/{str(i)}.png', compress_level=0)\n",
    "            location[i] = [x_center - width // 2, y_center - height // 2]\n",
    "    \n",
    "    # 经过以上的步骤，利用孪生神经网络按照顺序依次判断目标汉字图片与背景图中检测的图片的文字相似度，找到相似度最高的图片的坐标位置\n",
    "    idx = []\n",
    "    for img_0 in target_imgs:\n",
    "        rate = []\n",
    "        for j in os.listdir('./test/images/'):\n",
    "            img_1 = Image.open(f'./test/images/{j}').convert('RGB')\n",
    "            img_0 = img_0.convert('RGB')\n",
    "            pred = check_diff(img_0=img_0, img_1=img_1, trf=trf, model=model, device=device)\n",
    "            rate.append(pred[0])\n",
    "        idx.append(np.argmin(rate))\n",
    "    \n",
    "    actions = ActionChains(driver)\n",
    "    \n",
    "    code_img = driver.find_element(By.XPATH, '/html/body/div[7]/div[1]/div[1]/div[2]/div/div/div[1]/div[1]')\n",
    "    for key in idx:\n",
    "        value = location[key]\n",
    "        actions.move_to_element_with_offset(code_img, value[0], value[1]).click().perform()\n",
    "        time.sleep(1)\n",
    "    \n",
    "    check = driver.find_element(By.XPATH, '/html/body/div[7]/div[1]/div[1]/div[2]/div/div/div[2]/div')\n",
    "    actions.click(check).perform()\n",
    "    \n",
    "    # driver.find_element(By.XPATH, '/html/body/div[7]/div[1]/div[1]/div[3]/div[1]/button[2]').click()\n",
    "    time.sleep(5)\n",
    "\n",
    "else:\n",
    "    # driver.refresh()\n",
    "    # driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "    #     \"source\": \"\"\"\n",
    "    #     Object.defineProperty(navigator, 'webdriver', {\n",
    "    #       get: () => undefined\n",
    "    #     })\n",
    "    #   \"\"\"\n",
    "    # })\n",
    "    # time.sleep(3)\n",
    "    # break\n",
    "    driver.close()\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf7962a8-523a-4c7c-ba70-6fb83286ab69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %run ./model/yolov5/detect.py --weight ./model/yolov5/runs/train/exp4/weights/best.pt --source D:/yolo_dataset/4DnS.jpg --device 0 --save-txt --conf-thres 0.5 --line-thickness 1 --img 320\n",
    "# %run ./model/yolov5/detect.py --weight ./model/yolov5/runs/train/exp4/weights/best.pt --source D:/yolo_dataset/background.jpg --save-txt --conf-thres 0.5 --line-thickness 1 --img 320 --project ./results/detect/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcdf961f-86dd-4820-8387-512c94ead823",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./classes.txt', 'w', encoding='utf-8') as f:\n",
    "    for c in classes:\n",
    "        f.write(c + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ae7c3-50c0-477e-adb1-212970d08423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spider",
   "language": "python",
   "name": "spider"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
