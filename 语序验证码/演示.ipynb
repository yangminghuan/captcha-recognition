{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32115b61-463e-408d-ab5e-26af43668b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取验证码背景图片，利用yolov5模型进行目标汉字检测，得到汉字坐标位置并剪切对应汉字图片保存\n",
    "# 利用模型对汉字图片进行识别，得到相应的汉字列表\n",
    "# 基于jieba分词和n-gram模型判断汉字列表的排序组合，得到最有可能的汉字排序组合，最后输出对应的坐标位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11c48acd-9a39-45e9-91e4-06a75d1ae6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "import requests\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "from PIL import ImageChops\n",
    "import string\n",
    "import shutil\n",
    "import math\n",
    "import jieba\n",
    "from itertools import permutations\n",
    "import kenlm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d850a7ec-955c-4ccd-90f1-b943688f4ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得汉字的所有排列方式\n",
    "def _permutation(s, r = None): \n",
    "    word_list = list(permutations(s, r))\n",
    "    for i in range(len(word_list)):\n",
    "        word_list[i] = ''.join(word_list[i])\n",
    "    return word_list\n",
    "\n",
    "# 寻找列表中最长的词\n",
    "def find_longest(list):\n",
    "    l = 0\n",
    "    index = 0\n",
    "    for i,word in enumerate(list):\n",
    "        if len(word) > l:\n",
    "            l = len(word)\n",
    "            index = i \n",
    "    return index\n",
    "\n",
    "# 结巴分词 识别语序\n",
    "def recog_order_jieba(s):\n",
    "    l = len(s)  # l表示输入字符串个数\n",
    "    word_list = _permutation(s)  # 获得该字符串的所有排列方式\n",
    "    possible_words = []  # 用来存放语序可能正确的词\n",
    "    for word in word_list:  # 编列所有排列方式\n",
    "        seg_list = jieba.lcut(word, cut_all=True)  # 对某一种排列方式使用结巴分词\n",
    "        index = find_longest(seg_list)  # 寻找结巴分词返回的列表中字符串最长的索引，并返回\n",
    "        if len(seg_list[index]) == l:  # 若最长的字符串与输入的字符串长度相同，则加入可能正确列表\n",
    "            possible_words.append(seg_list[index])\n",
    "    if len(possible_words) == 1:  # 遍历完后，若可能正确的列表只有一个元素，那么他就是正确的，返回\n",
    "        return possible_words[0]\n",
    "    else:  # 如果可能正确的列表元素为0，则返回0\n",
    "        return 0\n",
    "\n",
    "def recog_order(s, lm):\n",
    "    # jieba识别\n",
    "    res = recog_order_jieba(s)\n",
    "    if res != 0:\n",
    "        return list(res)\n",
    "    else:\n",
    "        best_word = ''\n",
    "        word_list = _permutation(s)\n",
    "        score_max = -1e5\n",
    "        for word in word_list:\n",
    "            score = lm.score(' '.join(list(word)))\n",
    "            if score > score_max:\n",
    "                score_max = score\n",
    "                best_word = word\n",
    "        return list(best_word)\n",
    "\n",
    "class ImgClassifyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, class_num, pretrained=None):\n",
    "        super().__init__()\n",
    "        self.model = models.efficientnet_b5(pretrained=False)\n",
    "        # self.model = models.efficientnet_b7(pretrained=False)\n",
    "        if pretrained:\n",
    "            self.model.load_state_dict(torch.load(pretrained))\n",
    "        # self.model.classifier.add_module('3', nn.Linear(1000, class_num))\n",
    "        self.model.classifier[1] = nn.Linear(2048, class_num)\n",
    "        # self.model.classifier[1] = nn.Linear(2560, class_num)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def recog_chars(img_path, model, trf, device):\n",
    "    test_imgs = None\n",
    "    for i in os.listdir(img_path):\n",
    "        img = Image.open(f'{img_path}{i}').convert('RGB')\n",
    "        img = trf(img)\n",
    "        img = img.unsqueeze(0)\n",
    "        if test_imgs is None:\n",
    "            test_imgs = img\n",
    "        else:\n",
    "            test_imgs = torch.cat((test_imgs, img), dim=0)\n",
    "    test_imgs = test_imgs.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    pred_y = model(test_imgs)\n",
    "    pred_y = pred_y.detach().argmax(dim=-1).cpu().numpy()\n",
    "    \n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb12ce51-6765-4d2e-8d1e-e0eeb3219425",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = os.listdir('./classes/')\n",
    "label_to_char = dict(enumerate(chars))\n",
    "char_to_label = dict([(j, i) for i, j in label_to_char.items()])\n",
    "\n",
    "img_size = (112, 112)\n",
    "norm_mean = [0.485, 0.456, 0.406]\n",
    "norm_std = [0.229, 0.224, 0.225]\n",
    "trf = transforms.Compose([\n",
    "    transforms.Resize(img_size), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=norm_mean, std=norm_std)\n",
    "])\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "class_num = 899\n",
    "model_path = './model/model_0802.pt'\n",
    "lm = kenlm.Model('D:/Boost/zh_giga.no_cna_cmn.prune01244.klm')\n",
    "model = ImgClassifyModel(class_num=class_num, pretrained=None)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c4ceb88-ce74-4bcd-bc92-f9eba0c0c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ChromeOptions()\n",
    "options.add_argument('user-agent=\"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36\"')\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--ssl-protocol=any')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_argument('user-agent=ywy')\n",
    "options.add_argument('--ignore-urlfetcher-cert-requests')\n",
    "options.add_argument('--ignore-ssl-errors')\n",
    "options.add_experimental_option('excludeSwitches', ['enable-automation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "566baf7a-195e-4f46-abe9-d769a8899e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
      "WARNING  'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
      "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
      "    import torch\n",
      "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
      "    torch.save(ckpt, \"updated-model.pt\")\n",
      "\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['./model/yolov5/runs/train/exp4/weights/best.pt'], source=D:/yolo_dataset/background.jpg, data=model\\yolov5\\data\\coco128.yaml, imgsz=[320, 320], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=cpu, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=./results/detect/, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5  v7.0-196-gacdf73b Python-3.8.13 torch-1.10.1+cu102 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 267 layers, 46108278 parameters, 0 gradients, 107.6 GFLOPs\n",
      "image 1/1 D:\\yolo_dataset\\background.jpg: 224x320 3 chars, 224.0ms\n",
      "Speed: 0.0ms pre-process, 224.0ms inference, 1.0ms NMS per image at shape (1, 3, 320, 320)\n",
      "Results saved to \u001b[1mresults\\detect\\exp15\u001b[0m\n",
      "1 labels saved to results\\detect\\exp15\\labels\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ymh\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.547 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(options=options)\n",
    "driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "    \"source\": \"\"\"\n",
    "    Object.defineProperty(navigator, 'webdriver', {\n",
    "      get: () => undefined\n",
    "    })\n",
    "  \"\"\"\n",
    "})\n",
    "driver.get('https://www.gsxt.gov.cn/index.html')\n",
    "time.sleep(5)\n",
    "\n",
    "input_box = driver.find_element(By.ID, 'keyword')\n",
    "input_box.send_keys('德信行')\n",
    "time.sleep(1)\n",
    "driver.find_element(By.ID, 'btn_query').click()\n",
    "time.sleep(3)\n",
    "\n",
    "box = driver.find_element(By.XPATH, '/html/body/div[7]/div[1]/div[1]/div[1]/div[1]/div[1]')\n",
    "text = box.get_attribute('innerText')\n",
    "if text == '请按语序依次点击':\n",
    "\n",
    "    # s = ''.join(random.sample(string.ascii_letters + string.digits, 4))\n",
    "    url = driver.find_element(By.XPATH, '/html/body/div[7]/div[1]/div[1]/div[2]/div/div/div[1]/div[1]').get_attribute('style')[23:-3]\n",
    "    content = requests.get(url).content\n",
    "    with open('./test/background.jpg', 'wb') as f:\n",
    "        f.write(content)\n",
    "    shutil.copy('./test/background.jpg', 'D:/yolo_dataset')\n",
    "    %run ./model/yolov5/detect.py --weight ./model/yolov5/runs/train/exp4/weights/best.pt --source D:/yolo_dataset/background.jpg --save-txt --conf-thres 0.5 --line-thickness 1 --img 320 --project ./results/detect/ --device cpu\n",
    "    background = Image.open(BytesIO(content))\n",
    "    width, height = background.size\n",
    "    num = len(os.listdir('./results/detect/'))\n",
    "    location = {}\n",
    "    with open(f'./results/detect/exp{str(num)}/labels/background.txt', 'r', encoding='utf8') as f:\n",
    "        # if len(f.readlines()) != 3:\n",
    "        #     print(i)\n",
    "        for i, line in enumerate(f):\n",
    "            box = line.split(' ')\n",
    "            x_center = width * float(box[1])  # 左上点的x坐标  \n",
    "            y_center = height * float(box[2])  # 左上点的y坐标\n",
    "            w = round(width * float(box[3]))  # 图片width\n",
    "            h = round(height * float(box[4]))  # 图片height\n",
    "            lefttopx = math.ceil(x_center - w / 2.0)\n",
    "            lefttopy = math.ceil(y_center - h / 2.0)\n",
    "            crop_img = background.crop((lefttopx, lefttopy, lefttopx + w, lefttopy + h))\n",
    "            # s = ''.join(random.sample(string.ascii_letters + string.digits, 5))\n",
    "            crop_img.save(f'./test/images/{str(i)}.png', compress_level=0)\n",
    "            location[i] = [x_center - width // 2, y_center - height // 2]\n",
    "    \n",
    "    pred_y = recog_chars(img_path='./test/images/', model=model, trf=trf, device=device)\n",
    "    result = [label_to_char[y] for y in pred_y]\n",
    "    res_order = recog_order(result, lm)\n",
    "    idx = [result.index(i) for i in res_order]\n",
    "\n",
    "    actions = ActionChains(driver)\n",
    "    \n",
    "    code_img = driver.find_element(By.XPATH, '/html/body/div[7]/div[1]/div[1]/div[2]/div/div/div[1]/div[1]')\n",
    "    for key in idx:\n",
    "        value = location[key]\n",
    "        actions.move_to_element_with_offset(code_img, value[0], value[1]).click().perform()\n",
    "        time.sleep(1)\n",
    "    \n",
    "    check = driver.find_element(By.XPATH, '/html/body/div[7]/div[1]/div[1]/div[2]/div/div/div[2]/div')\n",
    "    actions.click(check).perform()\n",
    "    # refresh = driver.find_element(By.XPATH, '/html/body/div[7]/div[1]/div[1]/div[3]/div[1]/button[2]')\n",
    "    # actions.click(refresh)\n",
    "    # actions.move_to_element_with_offset(refresh, 50, 50)\n",
    "    # actions.perform()\n",
    "    time.sleep(2)\n",
    "\n",
    "    # driver.find_element(By.XPATH, '/html/body/div[7]/div[1]/div[1]/div[3]/div[1]/button[2]').click()\n",
    "    # time.sleep(2)\n",
    "\n",
    "else:\n",
    "    # driver.refresh()\n",
    "    # driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "    #     \"source\": \"\"\"\n",
    "    #     Object.defineProperty(navigator, 'webdriver', {\n",
    "    #       get: () => undefined\n",
    "    #     })\n",
    "    #   \"\"\"\n",
    "    # })\n",
    "    # time.sleep(3)\n",
    "    # break\n",
    "    driver.close()\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8be40ae-781f-4a0c-9845-11f1a79b3f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f2c793-4c53-4bdf-b587-3a5391b590c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed7cfe6-9a32-46b5-9328-f12b4080e89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62471610-bbc3-4f3b-b96c-bcc7aef6e9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spider",
   "language": "python",
   "name": "spider"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
