{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1411fdfa-d36e-4064-ba6e-2e2d47eb91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f931aace-9959-4e35-85a0-5012f3933134",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "816c4f4f-de70-4719-9eeb-46f20bf423bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./flags.txt', 'r', encoding='utf8') as f:\n",
    "    flags = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3cf9eed-01de-4cf1-84a4-01ea01edeab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = flags.split('\\n')\n",
    "label_to_flag = dict(enumerate(flags))\n",
    "flag_to_label = dict([(j, i) for i, j in label_to_flag.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d93caff2-dd3f-4c53-b59b-22789578b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "idx = [i[:-5] for i in os.listdir('./dataset/')]\n",
    "labels = []\n",
    "unknow = []\n",
    "for p in os.listdir('./dataset/'):\n",
    "    with open(f'./dataset/{p}', 'r', encoding='utf8') as f:\n",
    "        label = json.load(f)\n",
    "        label = [item[0] for item in label['flags'].items() if item[1] is True]\n",
    "        if label[0] == 'unknow':\n",
    "            unknow.append(p[:-5])\n",
    "        else:\n",
    "            labels.append(label[0])\n",
    "idx = [i for i in idx if i not in unknow]\n",
    "labels = [flag_to_label[i] - 1 for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebbd97dc-0f4a-47d2-b176-e82bcc5a055c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3553"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c9ec1f2-aa90-47c3-91ec-21608d562371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "file_paths = ['./data4/'+i+'.png' for i in idx]\n",
    "train_imgs, val_imgs, train_labels, val_labels = train_test_split(file_paths, labels, test_size=0.3, stratify=labels, random_state=2023)\n",
    "val_imgs, test_imgs, val_labels, test_labels = train_test_split(val_imgs, val_labels, test_size=0.5, stratify=val_labels, random_state=2023)\n",
    "# val_imgs, test_imgs, val_labels, test_labels = train_test_split(val_imgs, val_labels, test_size=0.5, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d1cd6-3c4e-473c-91c8-9962f0705e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "433e3622-858a-415e-8fd5-b69569433c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "img_size = (112, 112)\n",
    "norm_mean = [0.485, 0.456, 0.406]\n",
    "norm_std = [0.229, 0.224, 0.225]\n",
    "# trf = transforms.Compose([\n",
    "#     transforms.Resize(img_size), \n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=norm_mean, std=norm_std)\n",
    "# ])\n",
    "trf_dict = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.RandomChoice([\n",
    "            transforms.RandomRotation(degrees=(-10, 10)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5)\n",
    "        ]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=norm_mean, std=norm_std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=norm_mean, std=norm_std)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=norm_mean, std=norm_std)\n",
    "    ])\n",
    "}\n",
    "class ImgDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_paths, labels, trf):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.trf = trf\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.img_paths[idx]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        img = self.trf(img)\n",
    "        target = self.labels[idx]\n",
    "        target = torch.tensor(target, dtype=torch.long)\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3fbccbd-e457-4420-bff5-6d95324d1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = ImgDataset(train_imgs, train_labels, trf_dict['train'])\n",
    "val_dataset = ImgDataset(val_imgs, val_labels, trf_dict['val'])\n",
    "test_dataset = ImgDataset(test_imgs, test_labels, trf_dict['test'])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size//2, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size//2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dd91844-1085-4582-8fec-9f2cf8223e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 112, 112])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for img, label in train_loader:\n",
    "    print(img.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17cf7ff6-fa1c-4252-b437-d93b34077163",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 90])\n"
     ]
    }
   ],
   "source": [
    "class ImgClassifyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, class_num, pretrained=None):\n",
    "        super().__init__()\n",
    "        self.model = models.efficientnet_b5(pretrained=False)\n",
    "        # self.model = models.efficientnet_b7(pretrained=False)\n",
    "        if pretrained:\n",
    "            self.model.load_state_dict(torch.load(pretrained))\n",
    "        # self.model.classifier.add_module('3', nn.Linear(1000, class_num))\n",
    "        self.model.classifier[1] = nn.Linear(2048, class_num)\n",
    "        # self.model.classifier[1] = nn.Linear(2560, class_num)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class_num = 90\n",
    "model_path = './model/efficientnet_b5_lukemelas-b6417697.pth'\n",
    "# model_path = None\n",
    "model = ImgClassifyModel(class_num=class_num, pretrained=model_path)\n",
    "\n",
    "inputs = torch.zeros((32, 3, 112, 112))\n",
    "outputs = model(inputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "067ef2fa-385e-4a66-8610-320b1adf8b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_acc(y, pred_y):\n",
    "    pred_y = pred_y.detach().argmax(dim=-1)\n",
    "    acc = (y == pred_y).cpu().numpy()\n",
    "    return acc.mean()\n",
    "\n",
    "def train(epoch, model, iterator, optimizer, loss_fct, scheduler=None, device='cpu'):\n",
    "    model.train()\n",
    "    step = 0\n",
    "    all_loss = 0\n",
    "    all_acc = 0\n",
    "    for img, label in iterator:\n",
    "        step += 1\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        pred = model(img)\n",
    "        loss = loss_fct(pred, label)\n",
    "        all_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        acc = eval_acc(label, pred)\n",
    "        all_acc += acc\n",
    "    \n",
    "    print(\"Epoch: {}, Train Loss: {:.4f}, Train Acc: {:.4f}\".format(epoch, all_loss / step, all_acc / step))\n",
    "\n",
    "def validate(epoch, model, iterator, loss_fct, device):\n",
    "    model.eval()\n",
    "    step = 0\n",
    "    all_loss = 0\n",
    "    all_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for img, label in iterator:\n",
    "            step += 1\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            pred = model(img)\n",
    "            loss = loss_fct(pred, label)\n",
    "            all_loss += loss.item()\n",
    "\n",
    "            acc = eval_acc(label, pred)\n",
    "            all_acc += acc\n",
    "    \n",
    "    print(\"Epoch: {}, Val Loss: {:.4f}, Val Acc: {:.4f}\".format(epoch, all_loss / step, all_acc / step))\n",
    "    return model, all_loss / step, all_acc / step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e355ae6-4786-47b6-a4af-51dcf70ae0a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train=============================\n",
      "Epoch: 1, Train Loss: 4.1492, Train Acc: 0.1057\n",
      "Epoch: 1, Val Loss: 5122851.4412, Val Acc: 0.0129\n",
      "===========================================\n",
      "Epoch: 2, Train Loss: 3.3710, Train Acc: 0.1943\n",
      "Epoch: 2, Val Loss: 113809.4559, Val Acc: 0.0129\n",
      "===========================================\n",
      "Epoch: 3, Train Loss: 2.6929, Train Acc: 0.3267\n",
      "Epoch: 3, Val Loss: 272.7396, Val Acc: 0.0129\n",
      "===========================================\n",
      "Epoch: 4, Train Loss: 2.1453, Train Acc: 0.4472\n",
      "Epoch: 4, Val Loss: 324.2922, Val Acc: 0.0500\n",
      "===========================================\n",
      "Epoch: 5, Train Loss: 1.9089, Train Acc: 0.5061\n",
      "Epoch: 5, Val Loss: 20.5827, Val Acc: 0.1971\n",
      "===========================================\n",
      "Epoch: 6, Train Loss: 1.5227, Train Acc: 0.5879\n",
      "Epoch: 6, Val Loss: 6.7400, Val Acc: 0.3460\n",
      "===========================================\n",
      "Epoch: 7, Train Loss: 0.9506, Train Acc: 0.7318\n",
      "Epoch: 7, Val Loss: 1.2755, Val Acc: 0.7048\n",
      "===========================================\n",
      "Epoch: 8, Train Loss: 0.6234, Train Acc: 0.8305\n",
      "Epoch: 8, Val Loss: 0.9924, Val Acc: 0.7471\n",
      "===========================================\n",
      "Epoch: 9, Train Loss: 0.4625, Train Acc: 0.8657\n",
      "Epoch: 9, Val Loss: 0.9051, Val Acc: 0.7548\n",
      "===========================================\n",
      "Epoch: 10, Train Loss: 0.4208, Train Acc: 0.8744\n",
      "Epoch: 10, Val Loss: 0.8533, Val Acc: 0.7621\n",
      "===========================================\n",
      "Epoch: 11, Train Loss: 0.3195, Train Acc: 0.9050\n",
      "Epoch: 11, Val Loss: 0.8364, Val Acc: 0.7750\n",
      "===========================================\n",
      "Epoch: 12, Train Loss: 0.2888, Train Acc: 0.9123\n",
      "Epoch: 12, Val Loss: 0.8167, Val Acc: 0.7897\n",
      "===========================================\n",
      "Epoch: 13, Train Loss: 0.2317, Train Acc: 0.9344\n",
      "Epoch: 13, Val Loss: 0.7617, Val Acc: 0.8121\n",
      "===========================================\n",
      "Epoch: 14, Train Loss: 0.2135, Train Acc: 0.9458\n",
      "Epoch: 14, Val Loss: 0.7453, Val Acc: 0.8195\n",
      "===========================================\n",
      "Epoch: 15, Train Loss: 0.2176, Train Acc: 0.9407\n",
      "Epoch: 15, Val Loss: 0.7397, Val Acc: 0.8232\n",
      "===========================================\n",
      "Epoch: 16, Train Loss: 0.1905, Train Acc: 0.9463\n",
      "Epoch: 16, Val Loss: 0.7420, Val Acc: 0.8213\n",
      "===========================================\n",
      "Epoch: 17, Train Loss: 0.2058, Train Acc: 0.9462\n",
      "Epoch: 17, Val Loss: 0.7417, Val Acc: 0.8195\n",
      "===========================================\n",
      "Epoch: 18, Train Loss: 0.1993, Train Acc: 0.9462\n",
      "Epoch: 18, Val Loss: 0.7476, Val Acc: 0.8176\n",
      "===========================================\n",
      "Epoch: 19, Train Loss: 0.1929, Train Acc: 0.9500\n",
      "Epoch: 19, Val Loss: 0.7480, Val Acc: 0.8195\n",
      "===========================================\n",
      "Epoch: 20, Train Loss: 0.1976, Train Acc: 0.9458\n",
      "Epoch: 20, Val Loss: 0.7501, Val Acc: 0.8195\n",
      "===========================================\n",
      "Epoch: 21, Train Loss: 0.1899, Train Acc: 0.9458\n",
      "Epoch: 21, Val Loss: 0.7476, Val Acc: 0.8176\n",
      "===========================================\n",
      "Epoch: 22, Train Loss: 0.1769, Train Acc: 0.9491\n",
      "Epoch: 22, Val Loss: 0.7474, Val Acc: 0.8213\n",
      "===========================================\n",
      "Epoch: 23, Train Loss: 0.1904, Train Acc: 0.9486\n",
      "Epoch: 23, Val Loss: 0.7473, Val Acc: 0.8213\n",
      "===========================================\n",
      "Epoch: 24, Train Loss: 0.1899, Train Acc: 0.9462\n",
      "Epoch: 24, Val Loss: 0.7473, Val Acc: 0.8213\n",
      "===========================================\n",
      "Epoch: 25, Train Loss: 0.1807, Train Acc: 0.9514\n",
      "Epoch: 25, Val Loss: 0.7472, Val Acc: 0.8195\n",
      "===========================================\n",
      "Epoch: 26, Train Loss: 0.1785, Train Acc: 0.9500\n",
      "Epoch: 26, Val Loss: 0.7456, Val Acc: 0.8232\n",
      "===========================================\n",
      "Epoch: 27, Train Loss: 0.2024, Train Acc: 0.9393\n",
      "Epoch: 27, Val Loss: 0.7467, Val Acc: 0.8232\n",
      "===========================================\n",
      "Epoch: 28, Train Loss: 0.1741, Train Acc: 0.9535\n",
      "Epoch: 28, Val Loss: 0.7467, Val Acc: 0.8213\n",
      "===========================================\n",
      "Epoch: 29, Train Loss: 0.1829, Train Acc: 0.9502\n",
      "Epoch: 29, Val Loss: 0.7464, Val Acc: 0.8232\n",
      "===========================================\n",
      "Epoch: 30, Train Loss: 0.2014, Train Acc: 0.9506\n",
      "Epoch: 30, Val Loss: 0.7459, Val Acc: 0.8213\n",
      "===========================================\n",
      "train finish=============================\n",
      "CPU times: total: 46min 13s\n",
      "Wall time: 24min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "epochs = 30\n",
    "lr = 0.0005\n",
    "# opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "opt = torch.optim.RMSprop(model.parameters(), alpha=0.9, momentum=0.9, lr=lr, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer=opt, step_size=6, gamma=0.1)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "best_model = None\n",
    "best_val_loss = 1e10\n",
    "best_val_acc = 1e-10\n",
    "\n",
    "print(\"start train=============================\")\n",
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch, model=model, iterator=train_loader, loss_fct=loss_func, optimizer=opt, device=device)\n",
    "    candidate_model, loss, acc = validate(epoch, model=model, iterator=val_loader, loss_fct=loss_func, device=device)\n",
    "    scheduler.step()\n",
    "    \n",
    "    if loss < best_val_loss and acc > best_val_acc:\n",
    "        best_model = candidate_model\n",
    "        best_val_loss, best_val_acc = loss, acc\n",
    "    \n",
    "    print(\"===========================================\")\n",
    "print(\"train finish=============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d4280ad-e2c4-4e6f-a7db-3ca6fd810ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7838235294117647"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.eval()\n",
    "test_acc = 0\n",
    "step = 0\n",
    "with torch.no_grad():\n",
    "    for img, label in test_loader:\n",
    "        step += 1\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        pred = best_model(img)\n",
    "        \n",
    "        acc = eval_acc(label, pred)\n",
    "        test_acc += acc\n",
    "\n",
    "test_acc / step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d27602a8-0ebb-45c6-ab1a-5ec229b58a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8231617647058824"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ba11dfc-e512-4a02-9370-769993c9335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(best_model.state_dict(), \"./model/model_0724.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f83bd48-f8f1-4928-bb76-625c7b415fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trf = transforms.Compose([\n",
    "    transforms.Resize(img_size), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=norm_mean, std=norm_std)\n",
    "])\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5c414bbb-9fb9-45d4-ab14-b722708509f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = Image.open('./10013.png').convert('RGB')\n",
    "test_img = trf(test_img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fae81c53-4932-402a-beef-4d9854d5bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = test_img.to(device)\n",
    "# model = ImgClassifyModel(class_num=class_num, pretrained=None)\n",
    "# model.load_state_dict(torch.load('./model/model_0724.pt'))\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9fe61937-397a-4ef2-8995-00f39814e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c63ed217-92a5-4798-bd34-4482d8c83002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.detach().argmax(dim=-1).cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "42e72417-c955-451f-a321-ab6ffddfc307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'unknow',\n",
       " 1: '鱼',\n",
       " 2: '鸟',\n",
       " 3: '熊猫',\n",
       " 4: '兔子',\n",
       " 5: '猫',\n",
       " 6: '鳄鱼',\n",
       " 7: '狗',\n",
       " 8: '猪',\n",
       " 9: '狮子',\n",
       " 10: '老虎',\n",
       " 11: '鸡',\n",
       " 12: '袋鼠',\n",
       " 13: '猴子',\n",
       " 14: '乌龟',\n",
       " 15: '羊',\n",
       " 16: '牛',\n",
       " 17: '蝴蝶',\n",
       " 18: '企鹅',\n",
       " 19: '瓢虫',\n",
       " 20: '鹿、梅花鹿',\n",
       " 21: '长颈鹿',\n",
       " 22: '骆驼',\n",
       " 23: '照相机',\n",
       " 24: '剪刀',\n",
       " 25: '钥匙',\n",
       " 26: '荡秋千',\n",
       " 27: '螺丝刀',\n",
       " 28: '铁轨',\n",
       " 29: '锅',\n",
       " 30: '鼠标',\n",
       " 31: '书',\n",
       " 32: '键盘',\n",
       " 33: '订书机',\n",
       " 34: '拱桥',\n",
       " 35: '锅铲',\n",
       " 36: '听诊器',\n",
       " 37: '笔、钢笔',\n",
       " 38: '冰箱',\n",
       " 39: '足球',\n",
       " 40: '轮胎',\n",
       " 41: '手表',\n",
       " 42: '斧头',\n",
       " 43: '方向盘',\n",
       " 44: '打印机',\n",
       " 45: '台灯',\n",
       " 46: '桌球',\n",
       " 47: '排插',\n",
       " 48: '梳子',\n",
       " 49: '救护车',\n",
       " 50: '电钻',\n",
       " 51: '望远镜',\n",
       " 52: '雨伞',\n",
       " 53: '积木、城堡积木',\n",
       " 54: '叉子',\n",
       " 55: '井盖',\n",
       " 56: '齿轮',\n",
       " 57: '轮船、船',\n",
       " 58: '袜子',\n",
       " 59: '头盔',\n",
       " 60: '火箭',\n",
       " 61: '钱包',\n",
       " 62: '红绿灯',\n",
       " 63: '口红',\n",
       " 64: '拉链',\n",
       " 65: '计算器',\n",
       " 66: '烟斗',\n",
       " 67: '大巴车、公交车',\n",
       " 68: '地球仪',\n",
       " 69: '喷泉池',\n",
       " 70: '牙刷、刷子',\n",
       " 71: '气球',\n",
       " 72: '手套',\n",
       " 73: '水壶',\n",
       " 74: '碗',\n",
       " 75: '针筒',\n",
       " 76: '苍蝇拍、电蚊拍',\n",
       " 77: '羽毛球',\n",
       " 78: '过山车',\n",
       " 79: '桌子',\n",
       " 80: '贝壳',\n",
       " 81: '眼镜、带着眼镜的人',\n",
       " 82: '轮椅',\n",
       " 83: '帽子、带着帽子的人',\n",
       " 84: '领带',\n",
       " 85: '音响',\n",
       " 86: '椅子',\n",
       " 87: '行李箱',\n",
       " 88: '摩托车',\n",
       " 89: '手电筒',\n",
       " 90: '纽扣'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572eaec0-e81f-424b-88be-a1aa7b32f921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b4d9f-3998-4900-a4ef-bfdd9d5a23ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spider",
   "language": "python",
   "name": "spider"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
